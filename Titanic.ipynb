{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"../input/gender_submission.csv\")\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nsns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='inferno')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For filling null values in categorical column with a particular mode"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.loc[train['Pclass']==3, 'Cabin'] = train.loc[train['Pclass']==3, 'Cabin'].fillna(value=train.loc[train['Pclass']==3, 'Cabin'].mode().iloc[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sns.countplot(train['Survived'],hue=train['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sns.pairplot(train,palette='coolwarm',hue='Sex')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[['Name','Sex','Cabin','Embarked','Ticket','Pclass','Age','SibSp','Parch','Fare','Survived']]\ntest = test[['Name','Sex','Cabin','Embarked','Ticket','Pclass','Age','SibSp','Parch','Fare']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_initials(name):\n    point = name.index('.')\n    res = ''\n    for i in range(point-1,-1,-1):\n        if name[i]==' ':\n            break\n        else:\n            res+=name[i]\n    res = res[len(res)-1::-1]\n    return res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Name'] = train['Name'].apply(lambda x: get_initials(x))\ntest['Name'] = test['Name'].apply(lambda x: get_initials(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Cabin'].fillna(value='None',inplace=True)\ntest['Cabin'].fillna(value='None',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Embarked'].fillna(value='None',inplace=True)\ntest['Embarked'].fillna(value='None',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler\ndef encode_features(train,test):\n    features = ['Name','Sex','Cabin','Embarked','Ticket']\n    comb = pd.concat([train[features],test[features]])\n    \n    for feature in features:\n        le = LabelEncoder()\n        le = le.fit(comb[feature])\n        train[feature] = le.transform(train[feature])\n        test[feature] = le.transform(test[feature])\n    return train,test\ntrain,test = encode_features(train,test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['Name','Sex','Cabin','Embarked','Ticket']\ntrain = pd.get_dummies(train,columns=features,drop_first=True)\ntest = pd.get_dummies(test,columns=features,drop_first=True)\nmissing_cols = set( train.columns ) - set( test.columns )\nfor c in missing_cols:\n    test[c] = 0\ntest = test[train.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import Imputer\nimputer = Imputer(missing_values=np.nan,strategy='mean',axis=0)\nimputer = imputer.fit(train.iloc[:,:5])\ntrain.iloc[:,:5] = imputer.transform(train.iloc[:,:5])\ntest.iloc[:,:5] = imputer.transform(test.iloc[:,:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.info())\nprint()\nprint(train.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train['Survived'].values\nx_train = train.drop('Survived',axis=1).values\ntest = test.drop('Survived',axis=1).values\n#x_train = np.concatenate((a_train,b_train),axis=1)\n#test = np.concatenate((a_test,b_test),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"from sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler()\nsc = sc.fit(x_train)\nx_train = sc.transform(x_train)\ntest = sc.transform(test)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x_train,y_train,test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ML Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=300)\n\n#from xgboost import XGBClassifier\n#model = XGBClassifier()\n\n#from sklearn.svm import SVC\n#model = SVC(kernel='linear')\n\n#from sklearn.linear_model import LogisticRegression\n#model = LogisticRegression()\n\nmodel.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"from keras.models import Sequential\nfrom keras.layers import Dense,Dropout\n\nmodel = Sequential()\n\nmodel.add(Dense(output_dim=10,init='uniform',activation='relu',input_dim=852))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(output_dim=10,init='uniform',activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(output_dim=1,init='uniform',activation='sigmoid'))\n\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n\nmodel.fit(x_train,y_train,batch_size=20,epochs=15)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"from keras.models import Sequential\nfrom keras.layers import Dense,Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\n\ndef build(optimizer):\n    model = Sequential()\n    model.add(Dense(output_dim=10,init='uniform',activation='relu',input_dim=852))\n    model.add(Dropout(0.2))\n    model.add(Dense(output_dim=10,init='uniform',activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(output_dim=1,init='uniform',activation='sigmoid'))\n    model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n    return model\n\nmodel = KerasClassifier(build_fn=build)\n\nparameters = [{'batch_size':[10,20,30] ,\n              'epochs':[5,10,20,15] , \n              'optimizer':['adam']}]\n\ngrid_search = GridSearchCV(estimator=model,param_grid=parameters,scoring='accuracy',cv=10)\n\ngrid_search = grid_search.fit(x_train,y_train)\"\"\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#best_params = grid_search.best_params_\n#print(best_params)\n#print(grid_search.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(x_test)\n#pred = grid_search.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\npred = pred>0.5\nprint(classification_report(y_test,pred))\nprint()\nprint(confusion_matrix(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(test)\n#predictions = grid_search.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/test.csv')\nfinal = submission[['PassengerId']].copy()\nfinal['Survived'] = predictions\ndel submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final['Survived'] = final['Survived'] > 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def nums(value):\n    if value==False:\n        value = '0'\n    else:\n        value = '1'\n    return value\nfinal['Survived'] = final['Survived'].apply(lambda x :nums(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.to_csv('titanic_pred.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}